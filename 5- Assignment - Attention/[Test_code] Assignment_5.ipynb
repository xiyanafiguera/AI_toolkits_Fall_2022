{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OkXHWdTGxFQk",
        "8GA5E8VMxQYK",
        "DDicK-kCx4e_",
        "_01j_yoGyoN2",
        "43b5Ie1A0es1",
        "Tfg7Meo6cqfm",
        "lAqtPDKJdNWJ",
        "M4KMBqC5MYDV",
        "mk1x1iZPNDvC",
        "BStDwiHkNO7r"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Download meta.json and test set "
      ],
      "metadata": {
        "id": "vEJj2WFYRMbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "\n",
        "### Please, uncomment and change url below if downloading Test file from drive link\n",
        "\n",
        "#valid4test_url = 'https://drive.google.com/uc?id=1T5UFbIWq8IA5ox0upGcpxtTRyJwakxwI'\n",
        "#gdown.download(valid4test_url, './test.json')\n",
        "\n",
        "# Download meta.json\n",
        "meta_url = 'https://drive.google.com/uc?id=15Z_ziRMWthc2GMjeg612wAHbPA451CBu' #meta.json from my drive\n",
        "gdown.download(meta_url, './meta.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "dDIzVcq8RYjM",
        "outputId": "5a0e0a3d-1721-4aa6-a172-da7e77b5d039"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T5UFbIWq8IA5ox0upGcpxtTRyJwakxwI\n",
            "To: /content/test.json\n",
            "100%|██████████| 112k/112k [00:00<00:00, 48.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15Z_ziRMWthc2GMjeg612wAHbPA451CBu\n",
            "To: /content/meta.json\n",
            "100%|██████████| 147k/147k [00:00<00:00, 82.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./meta.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download pretrained embedding and unzip"
      ],
      "metadata": {
        "id": "OkXHWdTGxFQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-oLUhQaXS9B",
        "outputId": "c00a3bd6-e61a-48b8-b9bb-b667c4c7d5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-21 12:18:44--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2022-12-21 12:18:44--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2022-12-21 12:18:45--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.05MB/s    in 3m 23s  \n",
            "\n",
            "2022-12-21 12:22:09 (4.05 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import needed libraries"
      ],
      "metadata": {
        "id": "8GA5E8VMxQYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "OdyzIJW8VJUr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load embedding, meta data and set device"
      ],
      "metadata": {
        "id": "DDicK-kCx4e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove = pd.read_csv('glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
        "glove_embedding = {key: val.values for key, val in glove.T.items()}\n",
        "\n",
        "\n",
        "vocabulary_path = './meta.json'\n",
        "input_data = json.load(open(vocabulary_path, 'r'))\n",
        "vocabulary = input_data['tokens']\n",
        "#print(len(vocabulary))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "pjLPA5FkyOVa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create embedding matrix and index dictionary"
      ],
      "metadata": {
        "id": "_01j_yoGyoN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(vocabulary,embedding_dict,dimension):\n",
        "  \n",
        "  embedding_matrix=np.zeros((len(vocabulary)+1,dimension))\n",
        " \n",
        "  index = 1\n",
        "  total_added = 0\n",
        "  for word in vocabulary:\n",
        "    \n",
        "    if word in embedding_dict:\n",
        "      \n",
        "      embedding_matrix[index]=embedding_dict[word]\n",
        "      vd =dict(list(enumerate(vocabulary)))\n",
        "      dictionary = dict((v,k) for k,v in vd.items())\n",
        "            \n",
        "      index += 1\n",
        "      total_added += 1 \n",
        "\n",
        "  #print(\"total added words: \", total_added)\n",
        "  return embedding_matrix, dictionary\n",
        "\n",
        "embedding_matrix, dictionary=create_embedding_matrix(vocabulary,embedding_dict=glove_embedding,dimension=100)\n",
        "embedding_matrix = torch.tensor(embedding_matrix)\n",
        "#print(embedding_matrix.shape)\n",
        "\n",
        "#print(dict(itertools.islice(dictionary.items(), 10)))\n",
        "dictionary = Counter(dictionary)\n",
        "dictionary.update(dictionary.keys())\n",
        "#print(dict(itertools.islice(dictionary.items(), 10)))\n"
      ],
      "metadata": {
        "id": "HGZLaPcxWpjC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load test dataset"
      ],
      "metadata": {
        "id": "43b5Ie1A0es1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class test_text_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, x):\n",
        "\n",
        "        self.x = x\n",
        "        self.num_data = len(x)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        return (self.x[idx])\n",
        "\n",
        "def get_text(input_path):\n",
        "\n",
        "    input_data = json.load(open(input_path, 'r'))\n",
        "    sentence = [d['sentence'] for d in input_data]\n",
        "\n",
        "    return sentence\n",
        "\n",
        "def load_test_data():\n",
        "\n",
        "    test_path = './test.json'\n",
        "    \n",
        "    test_sentence = get_text(test_path)\n",
        "    \n",
        "    test_iter = test_text_Dataset(test_sentence)\n",
        "    \n",
        "    return test_iter, test_sentence"
      ],
      "metadata": {
        "id": "QbhWuNAa0Pd0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess text data (tokenization and indexing for embedding)"
      ],
      "metadata": {
        "id": "Tfg7Meo6cqfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline = lambda y: int(y) \n",
        "\n",
        "def text_pipeline(text):\n",
        "    \n",
        "    max_length = 50     #max length of sentences in data\n",
        "    sub_X = [0] * max_length\n",
        "\n",
        "    for idx, word in enumerate(text.split()):\n",
        "        if word in dictionary:\n",
        "              \n",
        "              if idx < max_length:\n",
        "                  sub_X[idx] = dictionary[word]\n",
        "\n",
        "    return sub_X\n"
      ],
      "metadata": {
        "id": "QohiggFBcle1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load test loader"
      ],
      "metadata": {
        "id": "lAqtPDKJdNWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_collate_batch(batch):\n",
        "\n",
        "    text_list, len_sentence = [], []\n",
        "\n",
        "    for _text in batch:\n",
        "    \n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         len_sen = len(_text.split())\n",
        "         if(len_sen>50):\n",
        "            len_sen = 50\n",
        "         len_sentence.append(len_sen)\n",
        "\n",
        "    len_sentence = torch.tensor(len_sentence)\n",
        "\n",
        "    text_list= torch.stack(text_list,dim=0)\n",
        "        \n",
        "    return text_list.to(device), len_sentence.to(device)\n",
        "\n",
        "test_iter, test_sentence = load_test_data()\n",
        "\n",
        "test_dataloader = DataLoader(test_iter, batch_size=256, shuffle=False,collate_fn=test_collate_batch) \n",
        "\n",
        "#sample = next(iter(test_dataloader))\n",
        "#print(sample)"
      ],
      "metadata": {
        "id": "ozp_poBadRTr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention module"
      ],
      "metadata": {
        "id": "FEVA5X6jLq4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self,hidden_size):              \n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.W_s1 = nn.Linear(2*hidden_size, 350)\n",
        "        self.W_s2 = nn.Linear(350, 30)\n",
        "        \n",
        "\n",
        "    def forward(self, lstm_output, lenghts):\n",
        "        \n",
        "        max_len = lstm_output.size()[1]\n",
        "        \n",
        "        attn_weight_matrix = self.W_s2(F.tanh(self.W_s1(lstm_output)))\n",
        "        attn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n",
        "        attn_weight_matrix = F.softmax(attn_weight_matrix, dim=2)\n",
        "        \n",
        "        _ = 0\n",
        "\n",
        "        mask = torch.ones(attn_weight_matrix.size(), requires_grad=True).cuda()\n",
        "        #mask = torch.ones(attn_weight_matrix.size(), requires_grad=False).cuda()\n",
        "        \n",
        "        for i, l in enumerate(lenghts):  \n",
        "            \n",
        "             if l < max_len:\n",
        "                 mask[i, l:] = 0\n",
        "            \n",
        "               \n",
        "        \n",
        "        attn_weight_matrix = attn_weight_matrix * mask\n",
        "\n",
        "        return attn_weight_matrix, _"
      ],
      "metadata": {
        "id": "vbCksGA4Xdus"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM model"
      ],
      "metadata": {
        "id": "M4KMBqC5MYDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super(RNN,self).__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
        "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim,bidirectional=True,dropout=0.1)   \n",
        "\n",
        "        self.atten1 = Attention(hidden_size=hidden_dim)     \n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc = torch.nn.Linear(12000, output_dim)\n",
        "       \n",
        "        \n",
        "\n",
        "    def forward(self, text, len_sentence):\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        length = len_sentence.cpu().to(dtype=torch.int64)\n",
        "\n",
        "        embedded = nn.utils.rnn.pack_padded_sequence(embedded, length, batch_first=True,enforce_sorted=False)\n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        out, lengths = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        x, _ = self.atten1(out,lengths)\n",
        "        hidden_matrix = torch.bmm(x, out)\n",
        "        \n",
        "        x = hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2])\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "       \n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "SDMRMyOsGzvZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set model"
      ],
      "metadata": {
        "id": "mk1x1iZPNDvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = 8\n",
        "vocab_size = embedding_matrix.shape[0]\n",
        "emsize = embedding_matrix.shape[1]\n",
        "hidden_size = 2 * emsize \n",
        "\n",
        "model = RNN(input_dim=vocab_size,\n",
        "             embedding_dim=emsize,\n",
        "             hidden_dim=hidden_size,\n",
        "             output_dim=num_class).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdvVB1t6NBKH",
        "outputId": "bf9dae97-a34d-4189-82e4-f506566f5405"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-15217d2f177a>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count parameters"
      ],
      "metadata": {
        "id": "BStDwiHkNO7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"the total number of parameters in Millions is:  \", count_parameters(model)/1000000)"
      ],
      "metadata": {
        "id": "7GyMtk1mDwlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16366d57-9910-461b-c8ce-5cf5c8af2ffc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the total number of parameters in Millions is:   2.067088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and save results"
      ],
      "metadata": {
        "id": "kjdpPBW7OYso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Load pth model\n",
        "### predict label\n",
        "### save predictions to file result\n",
        "\n",
        "def predicting_labels(model, data_loader, device):\n",
        "\n",
        "    predicted_labels_list = []\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (text, len_sentence) in enumerate(data_loader):\n",
        "\n",
        "            text_ = text.to(device)\n",
        "            \n",
        "            logits = model(text_,len_sentence)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            predicted_labels_list.extend(predicted_labels.detach().cpu().numpy())\n",
        "\n",
        "    return predicted_labels_list\n",
        "\n",
        "def save_resulst(predicted_labels_list, test_sentence):\n",
        "\n",
        "    results = list()\n",
        "\n",
        "    for i in range(len(test_sentence)):\n",
        "        tmp_result = dict()\n",
        "        tmp_result['sentence'] = test_sentence[i]\n",
        "        tmp_result['user_id'] = int(predicted_labels_list[i])\n",
        "        results.append(tmp_result)\n",
        "\n",
        "    json.dump(results, open('./result.json', 'w'), indent=2)\n",
        "\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "model.eval()\n",
        "predicted_labels_list = predicting_labels(model, test_dataloader, device)\n",
        "\n",
        "save_resulst(predicted_labels_list, test_sentence)\n",
        "\n"
      ],
      "metadata": {
        "id": "nuZ0AXnFOXHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4180157b-9e6f-4815-e6d1-899313bd2144"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        }
      ]
    }
  ]
}
